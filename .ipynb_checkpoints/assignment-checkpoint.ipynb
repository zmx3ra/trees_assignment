{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Trees\n",
    "\n",
    "## Do two questions in total: \"Q1+Q2\" or \"Q1+Q3\"\n",
    "\n",
    "`! git clone https://github.com/ds3001f25/linear_models_assignment.git`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** Please answer the following questions in your own words.\n",
    "1. Why is the Gini a good loss function for categorical target variables? \n",
    "2. Why do trees tend to overfit, and how can this tendency be constrained? \n",
    "3. True or false, and explain: Trees only really perform well in situations with lots of categorical variables as features/covariates. \n",
    "4. Why don't most versions of classification/regression tree concept allow for more than two branches after a split?\n",
    "5. What are some heuristic ways you can examine a tree and decide whether it is probably over- or under-fitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** This is a case study about classification and regression trees.\n",
    "\n",
    "1. Load the `Breast Cancer METABRIC.csv` dataset. How many observations and variables does it contain? Print out the first few rows of data.\n",
    "\n",
    "2.  We'll use a consistent set of feature/explanatory variables. For numeric variables, we'll include `Tumor Size`, `Lymph nodes examined positive`, `Age at Diagnosis`. For categorical variables, we'll include `Tumor Stage`, `Chemotherapy`, and `Cancer Type Detailed`. One-hot-encode the categorical variables and concatenate them with the numeric variables into a feature/covariate matrix, $X$.\n",
    "\n",
    "3. Let's predict `Overall Survival Status` given the features/covariates $X$. There are 528 missing values, unfortunately: Either drop those rows from your data or add them as a category to predict. Constrain the minimum samples per leaf to 10. Print a dendrogram of the tree. Print a confusion matrix of the algorithm's performance. What is the accuracy? \n",
    "\n",
    "4. For your model in part three, compute three statistics:\n",
    "    - The **true positive rate** or **sensitivity**:\n",
    "        $$\n",
    "        TPR = \\dfrac{TP}{TP+FN}\n",
    "        $$\n",
    "    - The **true negative rate** or **specificity**:\n",
    "        $$\n",
    "        TNR = \\dfrac{TN}{TN+FP}\n",
    "        $$\n",
    "    Does your model tend to perform better with respect to one of these metrics?\n",
    "\n",
    "5. Let's predict `Overall Survival (Months)` given the features/covariates $X$. Use the train/test split to pick the optimal `min_samples_leaf` value that gives the highest $R^2$ on the test set (it's about 110). What is the $R^2$? Plot the test values against the predicted values. How do you feel about this model for clinical purposes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** This is a case study about trees using bond rating data. This is a dataset about bond ratings for different companies, alongside a bunch of business statistics and other data. Companies often have multiple reviews at different dates. We want to predict the bond rating (AAA, AA, A, BBB, BB, B, ..., C, D). Do business fundamentals predict the company's rating?\n",
    "\n",
    "1. Load the `./data/corporate_ratings.csv` dataset. How many observations and variables does it contain? Print out the first few rows of data.\n",
    "\n",
    "2.  Plot a histogram of the `ratings` variable. It turns out that the gradations of AAA/AA/A and BBB/BB/B and so on make it hard to get good results with trees. Collapse all AAA/AA/A ratings into just A, and similarly for B and C.\n",
    "\n",
    "3. Use all of the variables **except** Rating, Date, Name, Symbol, and Rating Agency Name. To include Sector, make a dummy/one-hot-encoded representation and include it in your features/covariates. Collect the relevant variables into a data matrix $X$. \n",
    "\n",
    "4. Do a train/test split of the data and use a decision tree classifier to predict the bond rating. Including a min_samples_leaf constraint can raise the accuracy and speed up computation time. Print a confusion matrix and the accuracy of your model. How well do you predict the different bond ratings?\n",
    "\n",
    "5. If you include the rating agency as a feature/covariate/predictor variable, do the results change? How do you interpret this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
